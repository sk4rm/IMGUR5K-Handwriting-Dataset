{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T21:49:49.601520Z",
     "start_time": "2024-08-14T21:49:49.562280Z"
    }
   },
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # I use AMD... ðŸ˜­\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize dataset directory",
   "id": "cb24d90f21c08e10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T21:49:50.764775Z",
     "start_time": "2024-08-14T21:49:50.761787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir = ''\n",
    "test_dir = ''   \n",
    "val_dir = ''"
   ],
   "id": "5e01ec44c313d9c8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize dataset",
   "id": "3908f1236557f8f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T21:49:51.931152Z",
     "start_time": "2024-08-14T21:49:51.927433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, word_dir):\n",
    "        self.image_dir = image_dir\n",
    "        with open(word_dir, 'r') as f:\n",
    "            self.words = json.load(f)\n",
    "        self.images = list(self.image_dir.glob('*.jpg'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Lambda(lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2RGB)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((256, 256))\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        assert idx <= len(self), 'Index out of range'\n",
    "        try:\n",
    "            rgb_img = self.transform(Image.open(self.images[idx]).convert('RGB'))\n",
    "            bw_img = self.transform(Image.open(self.images[idx]).convert('L'))\n",
    "            return rgb_img, bw_img\n",
    "        except Exception as e:\n",
    "            return torch.tensor(-1), torch.tensor(-1)\n",
    "    \n",
    "        # item = {'image': img, 'idx': idx, 'label': self.words[self.images[idx].name]}\n",
    "        # return item"
   ],
   "id": "362acd3572fd2161",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss function",
   "id": "582dd2ca84b52d59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. VGG19 Typeface classifier, C - Text Perceptual Loss\n",
    "- Perceptual loss computed from the feature maps at layer i denoted as Ï†i and Mi is the number of elements in the particular feature map which is used as normalization. Only computed for output image corresponding to original content.\n",
    "- Texture loss / style loss computed from Gram matrix of the feature maps.\n",
    "- Embedding-based loss computed from feature maps of the penultimate layer of this network. (???)\n",
    "\n",
    "https://gist.github.com/alper111/8233cdb0414b4cb5853f2f730ab95a49#gistcomment-3347450"
   ],
   "id": "9ee389dd203780c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T21:49:53.930847Z",
     "start_time": "2024-08-14T21:49:53.923738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paper trains this model with Synth-Font dataset, however I could not find it\n",
    "class VGGPerceptualLoss(torch.nn.Module):\n",
    "    def __init__(self, resize=True):\n",
    "        super(VGGPerceptualLoss, self).__init__()\n",
    "        blocks= [torchvision.models.vgg19(pretrained=True).features[:4].eval(),\n",
    "                 torchvision.models.vgg19(pretrained=True).features[4:9].eval(),\n",
    "                 torchvision.models.vgg19(pretrained=True).features[9:16].eval(),\n",
    "                 torchvision.models.vgg19(pretrained=True).features[16:23].eval()]\n",
    "        for bl in blocks:\n",
    "            for p in bl.parameters():   \n",
    "                p.requires_grad = False\n",
    "        self.blocks = torch.nn.ModuleList(blocks)\n",
    "        self.transform = torch.nn.functional.interpolate\n",
    "        self.resize = resize\n",
    "        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
    "        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
    "    \n",
    "    # default: feature_layers=[0, 1, 2, 3], style_layers=[]    \n",
    "    def forward(self, prediction, target, feature_layers=None, style_layers=None):    \n",
    "        if style_layers is None:\n",
    "            style_layers = [0, 1, 2, 3]\n",
    "        if feature_layers is None:\n",
    "            feature_layers = [2]\n",
    "        if prediction.shape[1] != 3:\n",
    "            prediction = prediction.repeat(1, 3, 1, 1)\n",
    "            target = target.repeat(1, 3, 1, 1)\n",
    "        prediction = (prediction - self.mean) / self.std\n",
    "        target = (target-self.mean)/self.std\n",
    "        if self.resize:\n",
    "            prediction = self.transform(prediction, mode='bilinear', size=(224, 224), align_corners=False)\n",
    "            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n",
    "        loss = 0.0\n",
    "        x = prediction\n",
    "        y = target\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            y = block(y)\n",
    "            if i in feature_layers:\n",
    "                loss += torch.nn.functional.l1_loss(x, y)\n",
    "            if i in style_layers:\n",
    "                act_x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "                act_y = y.reshape(y.shape[0], y.shape[1], -1)\n",
    "                gram_x = act_x @ act_x.permute(0, 2, 1)\n",
    "                gram_y = act_y @ act_y.permute(0, 2, 1)\n",
    "                loss += torch.nn.functional.l1_loss(gram_x, gram_y)\n",
    "        return loss"
   ],
   "id": "283cb2611445278",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. OCR, R - Text Content Loss\n",
    "- The relevant modules has already been added along with the saved configuration mentioned in the paper, and the PyTorch model can be downloaded [here](https://drive.google.com/file/d/1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9/view?usp=drive_link). Have not implemented it to calculate loss yet.\n",
    "- The content loss is computed by measuring the cross entropy between the sequence of characters in the input string, c1, c2, the predicted string, c'1, c'2 respectively and are represented as one-hot vectors.\n",
    "\n",
    "https://github.com/clovaai/deep-text-recognition-benchmark"
   ],
   "id": "dd0b230c5ac13059"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch import nn\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        "
   ],
   "id": "945cefc6b55fd68d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T23:37:23.756529Z",
     "start_time": "2024-08-14T23:37:23.434417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ocr\n",
    "import argparse\n",
    "from ocr.utils import AttnLabelConverter\n",
    "from ocr.model import Model\n",
    "\n",
    "class opt:\n",
    "    # Hardcoding the arguments instead of using argument parsers \n",
    "    # as per https://github.com/clovaai/deep-text-recognition-benchmark/blob/master/demo.py#L96\n",
    "    image_folder = 'images'\n",
    "    workers = 4\n",
    "    batch_size = 192\n",
    "    saved_model = 'ocr/TPS-ResNet-BiLSTM-Attn.pth'\n",
    "    batch_max_length = 25\n",
    "    imgH = 32\n",
    "    imgW = 100\n",
    "    rgb = False # See input_channel comment below\n",
    "    character = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    sensitive = True\n",
    "    PAD = True\n",
    "    Transformation = 'TPS'\n",
    "    FeatureExtraction = 'ResNet'\n",
    "    SequenceModeling = 'BiLSTM'\n",
    "    Prediction = 'Attn'\n",
    "    num_fiducial = 20\n",
    "    input_channel = 1\n",
    "    output_channel = 512\n",
    "    hidden_size = 256\n",
    "    \n",
    "    \n",
    "converter = AttnLabelConverter(opt.character)\n",
    "opt.num_class = len(converter.character)\n",
    "\n",
    "if opt.rgb:\n",
    "    opt.input_channel = 3 # This breaks loading, input_channel has to be 1, or rgb false\n",
    "\n",
    "model = Model(opt)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "mappings = torch.load(opt.saved_model, map_location=device)\n",
    "model.load_state_dict(mappings)\n",
    "# Need to load data, presumably through DataLoader(). Idk hows the input data like yet, so i hold this.\n",
    "#demo_loader = torch.utils.data.DataLoader(\n",
    "#       demo_data, batch_size=opt.batch_size,\n",
    "#       shuffle=False,\n",
    "#       num_workers=int(opt.workers),\n",
    "#       collate_fn=AlignCollate_demo, pin_memory=True)\n",
    "model.eval()\n",
    "\n",
    "# It's getting late, idk anymore, over to you\n"
   ],
   "id": "a8bcda5e268eb161",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (Transformation): TPS_SpatialTransformerNetwork(\n",
       "      (LocalizationNetwork): LocalizationNetwork(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (10): ReLU(inplace=True)\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (14): ReLU(inplace=True)\n",
       "          (15): AdaptiveAvgPool2d(output_size=1)\n",
       "        )\n",
       "        (localization_fc1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
       "      )\n",
       "      (GridGenerator): GridGenerator()\n",
       "    )\n",
       "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
       "      (ConvNet): ResNet(\n",
       "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (layer2): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "        (layer3): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layer4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
       "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (SequenceModeling): Sequential(\n",
       "      (0): BidirectionalLSTM(\n",
       "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): BidirectionalLSTM(\n",
       "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
       "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Prediction): Attention(\n",
       "      (attention_cell): AttentionCell(\n",
       "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
       "        (rnn): LSTMCell(294, 256)\n",
       "      )\n",
       "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Style Encoder\n",
    "This is a homebrew version of ResNet34 architecture,I have no idea if this works, but I am prepared to alter it in the events it fails. "
   ],
   "id": "d1f723138fb31fd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T16:19:38.498336Z",
     "start_time": "2024-08-14T16:19:38.493168Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 18,
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ],
   "id": "a24a8d6eb648d084"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "class StyleEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StyleEncoder, self).__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3), #256x256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #128x128\n",
    "            self._make_layer(self, ResidualBlock, 64, 128, stride=2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #64x64\n",
    "            self._make_layer(self, ResidualBlock, 128, 256, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #32x32\n",
    "            self._make_layer(self, ResidualBlock, 256, 512, stride=2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #16x16\n",
    "            self._make_layer(self, ResidualBlock, 512, 512, stride=2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1),\n",
    "        )\n",
    "        \n",
    "    def _make_layer(self, block, in_channels, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torchvision.ops.roi_align(input=self.layer_stack(x)) #1x1"
   ],
   "id": "8494437a481da690",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
